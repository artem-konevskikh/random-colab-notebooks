{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Generate text with Transformers\n",
        "\n",
        "Basic example how to generate text in Russian with `transformers` library"
      ],
      "metadata": {
        "id": "KA1E5qL9A_ng"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install transformers\n",
        "!pip install transformers"
      ],
      "metadata": {
        "cellView": "form",
        "id": "lvr1bVAp7vxW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "aFSFzFVp7hEw"
      },
      "outputs": [],
      "source": [
        "#@title Get Model\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "#@markdown If you need another model you can get it here https://huggingface.co/models?pipeline_tag=text-generation&sort=downloads <br />\n",
        "model = \"sberbank-ai/mGPT\" #@param [\"sberbank-ai/mGPT\", \"sberbank-ai/rugpt3small_based_on_gpt2\", \"sberbank-ai/rugpt3large_based_on_gpt2\"]\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model)\n",
        "model = AutoModelForCausalLM.from_pretrained(model, pad_token_id=tokenizer.eos_token_id)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Generation Parameters\n",
        "prompt = \"Чёрный кот в жёлтом дождевике стоял на тёмной улице \" #@param {type: \"string\"}\n",
        "max_length = 250 #@param {type: \"integer\"}\n",
        "top_p = 0.95 #@param {type: \"number\"}\n",
        "top_k = 60 #@param {type: \"integer\"}\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "8wQDY_GE8F2C"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Generate\n",
        "inputs = tokenizer(prompt, add_special_tokens=False, return_tensors=\"pt\")[\"input_ids\"]\n",
        "prompt_length = len(tokenizer.decode(inputs[0]))\n",
        "outputs = model.generate(inputs, max_length=max_length, do_sample=True, top_p=top_p, top_k=top_k)\n",
        "generated = prompt + tokenizer.decode(outputs[0])[prompt_length + 1 :]\n",
        "\n",
        "print(generated)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "98zQWCf58Sh8",
        "outputId": "7d3ad72d-da11-44e5-e7a5-e455245bfdd4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Чёрный кот в жёлтом дождевике стоял на тёмной улице …> А тётка Таня сидела по соседству. Она с кучей цветов возился у её дома. Они гуляли по городу. Таня, забыв про дождевик, спокойно подшаривала цветы на пергаменте и записывала их на лист бумаги.\n",
            "Кот с дымком в руках, в жёлтом пончо, лапками о стол\n",
            "Когда Таня спокойно сидела в своём коттеджном доме, его обитатели всё чаще начали обращаться к нему — как к другом. Нужно было спрашивать у неё, говорить, чтобы он пришёл ещё с кем-то пообщаться, но Таня оставила всё на потом.\n",
            "Так было только в начале пятидесятых годов. Когда на город перебрался новый хозяин, Таня переехала и, кажется, даже больше её не оставила. Но, когда в городе, как и в селе, начался период стихии, Таня оказалась одна.\n",
            "Позже стало ясно, что в одиночестве Тан\n"
          ]
        }
      ]
    }
  ]
}